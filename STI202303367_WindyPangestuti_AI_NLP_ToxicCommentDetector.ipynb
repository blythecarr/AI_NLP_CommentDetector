{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTSLEql48MZd0g155Ow3km",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blythecarr/NLP_ToxicCommentDetector/blob/main/STI202303367_WindyPangestuti_AI_NLP_ToxicCommentDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import library"
      ],
      "metadata": {
        "id": "jYJVhp_qx6dt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZk5Z5N_wyuf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load dataset"
      ],
      "metadata": {
        "id": "w1lVtAN7yPK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/Toxic Comment Moderation Dataset.xlsx\")"
      ],
      "metadata": {
        "id": "bvJCKd58yqPX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Ambil kolom penting dan rename"
      ],
      "metadata": {
        "id": "qCNtKR6Ky2qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['comment_text', 'is_toxic']].rename(columns={'comment_text': 'text', 'is_toxic': 'label'})\n",
        "df['label'] = df['label'].astype(int)"
      ],
      "metadata": {
        "id": "VN_38lfIzADJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Split data"
      ],
      "metadata": {
        "id": "T2-2ON1ezVpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "A0btB0R9zZ0S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. TF-IDF + PassiveAggressiveClassifier"
      ],
      "metadata": {
        "id": "stKlNXXLze96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(lowercase=True, stop_words='english', max_features=2000)\n",
        "X_tr = tfidf.fit_transform(X_train)\n",
        "X_va = tfidf.transform(X_val)\n",
        "\n",
        "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42)\n",
        "pac.fit(X_tr, y_train)\n",
        "\n",
        "y_pred = pac.predict(X_va)\n",
        "\n",
        "print(\"ðŸ”Ž Hasil Model TF-IDF + PAC\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred, target_names=['Benign', 'Toxic']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf1Ky4e_zjL9",
        "outputId": "cf902734-73e5-4dda-a9ff-b9e4bbbdf3c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”Ž Hasil Model TF-IDF + PAC\n",
            "Accuracy: 0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.94      0.96      0.95       138\n",
            "       Toxic       0.91      0.89      0.90        72\n",
            "\n",
            "    accuracy                           0.93       210\n",
            "   macro avg       0.93      0.92      0.93       210\n",
            "weighted avg       0.93      0.93      0.93       210\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. BERT EMBEDDING + PassiveAggressiveClassifier"
      ],
      "metadata": {
        "id": "ERxs4HlCzqH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    enc = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        outputs = bert(**enc)\n",
        "    return outputs.pooler_output.numpy()\n",
        "\n",
        "X_tr_bert = get_embeddings(X_train)\n",
        "X_va_bert = get_embeddings(X_val)\n",
        "\n",
        "pac_bert = PassiveAggressiveClassifier(max_iter=50, random_state=42)\n",
        "pac_bert.fit(X_tr_bert, y_train)\n",
        "y_pred_bert = pac_bert.predict(X_va_bert)\n",
        "\n",
        "print(\"\\nðŸ”Ž Hasil Model BERT + PAC\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_bert))\n",
        "print(classification_report(y_val, y_pred_bert, target_names=['Benign', 'Toxic']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P1uPBXezui-",
        "outputId": "6f5b0611-4d17-4b5d-c9d2-0cd65d9ff9c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”Ž Hasil Model BERT + PAC\n",
            "Accuracy: 0.9380952380952381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.96      0.95      0.95       138\n",
            "       Toxic       0.90      0.92      0.91        72\n",
            "\n",
            "    accuracy                           0.94       210\n",
            "   macro avg       0.93      0.93      0.93       210\n",
            "weighted avg       0.94      0.94      0.94       210\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Uji coba prediksi komentar baru"
      ],
      "metadata": {
        "id": "QkH18ZM30xm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text, method='tfidf'):\n",
        "    if method == 'tfidf':\n",
        "        x = tfidf.transform([text])\n",
        "        pred = pac.predict(x)[0]\n",
        "    elif method == 'bert':\n",
        "        emb = get_embeddings(pd.Series([text]))\n",
        "        pred = pac_bert.predict(emb)[0]\n",
        "    return \"Toxic\" if pred == 1 else \"Benign\"\n",
        "\n",
        "print(\"\\nðŸ§ª Contoh Uji Komentar\")\n",
        "sample_texts = [\n",
        "    \"Stop being so stupid.\"\n",
        "]\n",
        "\n",
        "for text in sample_texts:\n",
        "    print(f\"\\nKomentar: {text}\")\n",
        "    print(\"Prediksi TF-IDF + PAC  âžœ\", predict_text(text, method='tfidf'))\n",
        "    print(\"Prediksi BERT + PAC    âžœ\", predict_text(text, method='bert'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTu8cv4T03RZ",
        "outputId": "836e8882-afc9-44ab-a8f8-f0149990ccde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§ª Contoh Uji Komentar\n",
            "\n",
            "Komentar: Stop being so stupid.\n",
            "Prediksi TF-IDF + PAC  âžœ Toxic\n",
            "Prediksi BERT + PAC    âžœ Toxic\n"
          ]
        }
      ]
    }
  ]
}